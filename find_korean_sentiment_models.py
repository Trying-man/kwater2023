#!/usr/bin/env python3
"""
í•œêµ­ì–´ ê°ì •ë¶„ì„ì— ë¯¸ì„¸ì¡°ì •ëœ ëª¨ë¸ë“¤ì„ ì°¾ê³  í…ŒìŠ¤íŠ¸
"""

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import numpy as np
import time

def test_korean_sentiment_models():
    """í•œêµ­ì–´ ê°ì •ë¶„ì„ì— ë¯¸ì„¸ì¡°ì •ëœ ëª¨ë¸ë“¤ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    
    print("=" * 70)
    print("í•œêµ­ì–´ ê°ì •ë¶„ì„ íŠ¹í™” ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # í•œêµ­ì–´ ê°ì •ë¶„ì„ì— ë¯¸ì„¸ì¡°ì •ëœ ëª¨ë¸ë“¤
    korean_sentiment_models = [
        {
            "name": "snunlp/KR-FinBert-SC",
            "description": "í•œêµ­ì–´ ê¸ˆìœµ ê°ì •ë¶„ì„ ëª¨ë¸",
            "labels": ["negative", "neutral", "positive"]
        },
        {
            "name": "beomi/KcELECTRA-base-v2022",
            "description": "í•œêµ­ì–´ ELECTRA ëª¨ë¸ (ê°ì •ë¶„ì„ ë¯¸ì„¸ì¡°ì • ì—†ìŒ)",
            "labels": ["Negative", "Neutral", "Positive"]
        },
        {
            "name": "klue/roberta-base",
            "description": "KLUE RoBERTa ëª¨ë¸ (ê°ì •ë¶„ì„ ë¯¸ì„¸ì¡°ì • ì—†ìŒ)",
            "labels": ["Negative", "Neutral", "Positive"]
        },
        {
            "name": "monologg/koelectra-base-v3-discriminator",
            "description": "í•œêµ­ì–´ ELECTRA ëª¨ë¸ (ê°ì •ë¶„ì„ ë¯¸ì„¸ì¡°ì • ì—†ìŒ)",
            "labels": ["Negative", "Neutral", "Positive"]
        }
    ]
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ë“¤
    test_texts = [
        ("ë§¤ìš° ê¸ì •", "ì •ë§ ì¢‹ì€ ì†Œì‹ì…ë‹ˆë‹¤! í™˜ê²½ ë³´í˜¸ì— í¬ê²Œ ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
        ("ê¸ì •", "í•œêµ­ìˆ˜ìì›ê³µì‚¬ê°€ í˜ì‹ ì ì¸ ê¸°ìˆ ë¡œ í™˜ê²½ ë³´í˜¸ì— ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤."),
        ("ì¤‘ë¦½", "í•œêµ­ìˆ˜ìì›ê³µì‚¬ê°€ ìƒˆë¡œìš´ ëŒ ê±´ì„¤ í”„ë¡œì íŠ¸ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤."),
        ("ë¶€ì •", "ìˆ˜ì§ˆ ì˜¤ì—¼ ë¬¸ì œë¡œ ì¸í•´ ì£¼ë¯¼ë“¤ì´ ê±´ê°• ë¬¸ì œë¥¼ ê²ªê³  ìˆìŠµë‹ˆë‹¤."),
        ("ë§¤ìš° ë¶€ì •", "ì •ë§ ë”ì°í•œ ìƒí™©ì…ë‹ˆë‹¤! ìˆ˜ì§ˆ ì˜¤ì—¼ìœ¼ë¡œ ì¸í•´ ì£¼ë¯¼ë“¤ì´ ì‹¬ê°í•œ ê±´ê°• ë¬¸ì œë¥¼ ê²ªê³  ìˆìŠµë‹ˆë‹¤.")
    ]
    
    for model_info in korean_sentiment_models:
        model_name = model_info["name"]
        description = model_info["description"]
        labels = model_info["labels"]
        
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¤‘: {model_name}")
        print(f"   ì„¤ëª…: {description}")
        print(f"   ë¼ë²¨: {labels}")
        print("-" * 50)
        
        try:
            # ëª¨ë¸ ë¡œë”© ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModelForSequenceClassification.from_pretrained(
                model_name,
                num_labels=len(labels)
            )
            loading_time = time.time() - start_time
            print(f"   ë¡œë”© ì‹œê°„: {loading_time:.2f}ì´ˆ")
            
            # ë¶„ì„ ì‹œê°„ ì¸¡ì •
            analysis_start = time.time()
            
            results = []
            for emotion, text in test_texts:
                # í† í¬ë‚˜ì´ì§•
                inputs = tokenizer(
                    text,
                    return_tensors="pt",
                    truncation=True,
                    max_length=512,
                    padding=True
                )
                
                # ì˜ˆì¸¡
                with torch.no_grad():
                    outputs = model(**inputs)
                    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
                    scores = predictions[0].numpy()
                
                # ìµœê³  ì ìˆ˜ ì°¾ê¸°
                max_idx = np.argmax(scores)
                predicted_label = labels[max_idx]
                max_score = scores[max_idx]
                
                results.append({
                    "expected": emotion,
                    "predicted": predicted_label,
                    "score": max_score,
                    "scores": scores
                })
                
                print(f"   {emotion} â†’ {predicted_label} ({max_score:.3f})")
            
            analysis_time = time.time() - analysis_start
            print(f"   ë¶„ì„ ì‹œê°„: {analysis_time:.2f}ì´ˆ")
            
            # ì •í™•ë„ ê³„ì‚°
            correct = sum(1 for r in results if r["predicted"] != "neutral" and r["predicted"] != "Neutral")
            accuracy = correct / len(results) * 100
            print(f"   ì •í™•ë„: {accuracy:.1f}%")
            
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
        
        print()

if __name__ == "__main__":
    test_korean_sentiment_models()
